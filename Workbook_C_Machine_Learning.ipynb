{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "3.5.1"
    },
    "colab": {
      "name": "Workbook_C_Machine_Learning.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/camgenomicmedicine/GMO7-Jupyter/blob/main/Workbook_C_Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "304ecfd8"
      },
      "source": [
        "# Workbook C - Introduction to Machine Learning"
      ],
      "id": "304ecfd8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06804555"
      },
      "source": [
        "Welcome to the first Machine Learning (ML) practical. This practical is an introduction to the typical methods used in ML, using some very simply datasets. This practical is run in R. You can choose to either run this notebook in Jupyter using the R kernel, or to run the commands yourself in R. This practical is divided into three sections:\n",
        " \n",
        "1.   Visualising data\n",
        "2.   Supervised methods\n",
        "3.   Unsupervised methods"
      ],
      "id": "06804555"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2a02b75"
      },
      "source": [
        "## 1.0 Introduction to Machine Learning - visualising data"
      ],
      "id": "b2a02b75"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ebf1f23"
      },
      "source": [
        "Before we do any ML we need to understand the advantages that it can bring us. This is fundamentally about understanding the difference between a static data report and a data model. \n",
        "\n",
        "Models are helpful because unlike reports, which offer a static picture of what the data shows currently, models can go further and help you understand the future. For example, someone who is performing a single experiment might only be familiar with reports that show a static picture. Maybe their analysis report is always up to date with what the current sample is. Let's see an example of a report using the built in `mtcars` dataset. It contains data about 32 cars from a 1974 issue of Motor Trend magazine."
      ],
      "id": "9ebf1f23"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "403304db"
      },
      "source": [
        "op <- par(mar = c(10, 4, 4, 2) + 0.1)  #margin formatting\n",
        "\n",
        "barplot(mtcars$mpg, names.arg = row.names(mtcars), las = 2, ylab = \"Fuel\n",
        "Efficiency in Miles per Gallon\")"
      ],
      "id": "403304db",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a017ab91"
      },
      "source": [
        "This dataset is prebuilt into R. Your figure above should show a number of cars plotted by their fuel efficiency in miles per gallon. This report isn’t very interesting. It doesn’t give us any predictive power. Seeing how the efficiency of the cars is distributed is nice, but how can we relate that to other things in the data and, moreover, make predictions from it?\n",
        "\n",
        "A **model** is any sort of function that has predictive power.\n",
        "\n",
        "So how do we turn this boring report into something more useful? How do we bridge the gap between reporting and machine learning? Oftentimes the correct answer to this is “more data!” That can come in the form of more observations of the same data or by collecting new types of data that we can then use for comparison.\n",
        "\n",
        "Let’s take a look at the built-in `mtcars` dataset that comes with R in more detail:"
      ],
      "id": "a017ab91"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18e9bb9e"
      },
      "source": [
        "head(mtcars)"
      ],
      "id": "18e9bb9e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "100a66b9"
      },
      "source": [
        "By just calling the built-in object of mtcars within R, we can see all sorts of columns in the data from which to choose to build a machine learning model. In the machine learning world, columns of data are sometimes also called features. Now that we know what we have to work with, we could try seeing if there’s a relationship between the car’s fuel efficiency and any one of these features using a pairs plot."
      ],
      "id": "100a66b9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40f47832"
      },
      "source": [
        "pairs(mtcars[1:7], lower.panel = NULL)"
      ],
      "id": "40f47832",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8be8379e"
      },
      "source": [
        "Each box is its own separate plot, for which the dependent variable is the text box at the bottom of the column, and the independent variable is the text box at the beginning of the row. Some of these plots are more interesting for trending purposes than others. None of the plots in the `cyl` row, for example, look like they lend themselves easily to simple regression modeling."
      ],
      "id": "8be8379e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d8ce139"
      },
      "source": [
        "Here we are mostly interested in something that looks like it might have some kind of quantifiable relationship. This is up to the investigator to pick out what patterns look interesting. Note that “mpg as a function of cyl” looks very different from “mpg as a function of wt.” Let's focus on the latter and make a plot of it."
      ],
      "id": "5d8ce139"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99f13ec8"
      },
      "source": [
        "plot(y = mtcars$mpg, x = mtcars$wt, xlab = \"Vehicle Weight\",\n",
        "    ylab = \"Vehicle Fuel Efficiency in Miles per Gallon\")"
      ],
      "id": "99f13ec8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c454de04"
      },
      "source": [
        "#### Question 1\n",
        "Make the equivalent plot for `mpg` as a function of `cyl`"
      ],
      "id": "c454de04"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc1f7c5c"
      },
      "source": [
        "#put your code here"
      ],
      "id": "cc1f7c5c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a497978"
      },
      "source": [
        "Now we have a more interesting kind of dataset. We still have our fuel efficiency, but now it is plotted against the weight of the respective cars in tons. From this kind of format of the data, we can extract a best fit to all the data points and turn this plot into an equation. We use a function in R to model the value we’re interested in, called a response, against other features in our dataset:"
      ],
      "id": "4a497978"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5610ddd"
      },
      "source": [
        "mt.model <- lm(formula = mpg ~ wt, data = mtcars)\n",
        "\n",
        "coef(mt.model)[2]"
      ],
      "id": "f5610ddd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39487bcb"
      },
      "source": [
        "coef(mt.model)[1]"
      ],
      "id": "39487bcb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25c3a21f"
      },
      "source": [
        "In this code chunk, we modeled the vehicle’s fuel efficiency (mpg) as a function of the vehicle’s weight (wt) and extracted values from that model object to use in an equation that we can write as follows:\n",
        "\n",
        "Fuel Efficiency = 5.344 × Vehicle Weight + 37.285"
      ],
      "id": "25c3a21f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f46ca127"
      },
      "source": [
        "Now if we wanted to know what the fuel efficiency was for any car, not just those in the dataset, all we would need to input is the weight of it, and we get a result. This the benefit of a model. We have predictive power, given some kind of input (e.g., weight), that can give us a value for any number we put in.\n",
        "\n",
        "The model might have its limitations, but this is one way in which we can help to expand the data beyond a static report into something more flexible and more insightful. A given vehicle’s weight might not actually be predictive of the fuel efficiency as given by the preceding equation. There might be some error in the data or the observation.\n",
        "\n",
        "You might have come across this kind of modeling procedure before in dealing with the world of data. If you have, congratulations—you have been doing machine learning without even knowing it! This particular type of machine learning model is called linear regression. It’s much simpler than some other machine learning models like neural networks, but the algorithms that make it work are certainly using machine learning principles.\n",
        "\n",
        "A machine learning model like regression or clustering or neural networks relies on the workings of algorithms to help them run in the first place. \n",
        "\n",
        "There are three major types of models: regression models, classification models, and mixed models that are a combination of both. We’ve already encountered a regression model. A classification model is different in that we would be trying to take input data and arrange it according to a type, class, group, or other discrete output. Mixed models might start with a regression model and then use the output from that to help it classify other types of data. The reverse could be true for other mixed models.\n",
        "\n",
        "The function call for a simple linear regression in R can be written as: `lm(y ~ x)`, or read out loud as “give me the linear model for the variable `y` as a function of the feature `x`.” What you’re not seeing are the algorithms that the code is running to make optimizations based on the data that we give it.\n",
        "\n",
        "It’s very easy to become lost in the weeds of algorithms and statistics when you’re simply trying to understand what the difference between a logistic regression machine learning model is compared to a support vector machine model."
      ],
      "id": "f46ca127"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e737091"
      },
      "source": [
        "Although documentation in R can vary greatly in quality from one machine learning function to the next, in general, one can look up the inner workings of a model by pulling up the help file for it:"
      ],
      "id": "2e737091"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "349a190d"
      },
      "source": [
        "?(lm)"
      ],
      "id": "349a190d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f08cd118"
      },
      "source": [
        "#### A note on the function operator\n",
        "R offers a fantastic tool for helping with the modeling process, known as the function operator, `~`. This symbolic operator acts like an equals sign in a mathematical formula. Above we saw the example with a linear model in which we had `lm(mtcars$mpg ~ mtcars$wt)`. In that case, `mtcars$mpg` was our response, the item we want to model as the output, and `mtcars$wt` was the input. Mathematically, this would be like `y = f(x)` in mathematical notation compared with `y ~ x` in R code.\n",
        "\n",
        "This powerful operator makes it possible for you to utilize multiple inputs very easily. We might expect to encounter a multivariate function in mathematics to be written as follows:\n",
        "\n",
        "`y = f(x1, x2, x3, ...)`\n",
        "\n",
        "In R, that formulation is very straightforward:\n",
        "\n",
        "`y ~ x_1 + x_2 + x_3`\n",
        "\n",
        "What we are doing here is saying that our modeling output `y` is not only a function of `x_1`, but many other variables, as well. We will see in dedicated views of machine learning models how we can utilize multiple features or inputs in our models."
      ],
      "id": "f08cd118"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0971fede"
      },
      "source": [
        "#### Question 2\n",
        "Create a linear regression for `mpg` as a function of `hp` and print the coef and intercept"
      ],
      "id": "0971fede"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d4d4b07"
      },
      "source": [
        "#put your code here"
      ],
      "id": "5d4d4b07",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08eecdf7"
      },
      "source": [
        "## 2.0 Introduction to machine learning - supervised methods"
      ],
      "id": "08eecdf7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94635cbf"
      },
      "source": [
        "In the universe of machine learning algorithms, there are two major types: supervised and unsupervised. Supervised learning models are those in which a machine learning model is scored and tuned against some sort of known quantity. The majority of machine learning algorithms are supervised learners. Unsupervised learning models are those in which the machine learning model derives patterns and information from data while determining the known quantity tuning parameter itself. "
      ],
      "id": "94635cbf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c974ccb"
      },
      "source": [
        "#### Regression\n",
        "Regression modeling is something you most likely have done numerous times without realizing you’re doing machine learning. At its core, a regression line is one for which we fit to data that has an x and a y element. We then use an equation to predict what the corresponding output, y, should be for any given input, x. This is always done on numeric data.\n",
        "\n",
        "Let’s take a look at another example regression using the `mtcars` dataset. Let's plot the fuel efficiency of the cars (`mpg`) in the dataset as a function of their engine size, or displacement (`disp`) in cubic inches:"
      ],
      "id": "6c974ccb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36c09060"
      },
      "source": [
        "# finish this code cell to show the correct data\n",
        "plot(y = mtcars$ , x = mtcars$ , xlab = \"Engine Size (cubic inches)\",\n",
        "    ylab = \"Fuel Efficiency (Miles per Gallon)\")"
      ],
      "id": "36c09060",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "befe4c8a"
      },
      "source": [
        "We can see from the plot above that the fuel efficiency decreases as the size of the engine increases. However, if you have some new engine for which you want to know the efficiency, our plot doesn’t really give us an exact answer. For that, we need to build a linear model."
      ],
      "id": "befe4c8a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0648455c"
      },
      "source": [
        "model <- lm(mtcars$mpg ~ mtcars$disp)\n",
        "coef(model)"
      ],
      "id": "0648455c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6812c63"
      },
      "source": [
        "The cornerstone for regression modeling in R is the `lm()` function"
      ],
      "id": "c6812c63"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6312a09"
      },
      "source": [
        "Our linear model in this case is given by the coefficients that you just computed, so the model looks like the following:\n",
        "\n",
        "`Fuel Efficiency = –0.041 × Engine Size + 29.599`"
      ],
      "id": "f6312a09"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d684b152"
      },
      "source": [
        "You now have a very simple machine learning model! You can use any input for the engine size and get a value out. Let’s look at the fuel efficiency for a car with a 200-cubic-inch displacement:"
      ],
      "id": "d684b152"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74415c33"
      },
      "source": [
        "-0.041 * 200 + 25.599"
      ],
      "id": "74415c33",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "882fec6a"
      },
      "source": [
        "Another, more accurate, way to do this is to call the coefficients from the model directly:"
      ],
      "id": "882fec6a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be8d5950"
      },
      "source": [
        "coef(model)[2] * 200 + coef(model)[1]"
      ],
      "id": "be8d5950",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed9b98ff"
      },
      "source": [
        "#### Training and testing of data"
      ],
      "id": "ed9b98ff"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c81845c5"
      },
      "source": [
        "Before we jump into the other major realm of supervised learning, we need to bring up the topic about training and testing data. As we’ve seen with simple linear regression modeling thus far, we have a model that we can use to predict future values. Yet, we know nothing about how accurate the model is for the moment. One way to determine model accuracy is to look at the R-squared value from the model:"
      ],
      "id": "c81845c5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "261ddfd2"
      },
      "source": [
        "summary(model)"
      ],
      "id": "261ddfd2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "480b36fa"
      },
      "source": [
        "The accuracy parameter that’s most important to us at the moment is the `Adjusted R-squared value`. This value tells us how linearly correlated the data is; the closer the value is to 1, the more likely the model output is governed by data that’s almost exactly a straight line with some kind of slope value to it. The reason we are focusing on the adjusted part instead of the multiple is for future scenarios in which we use more features in a model. For low numbers of features the adjusted and multiple R-squared values are basically the same thing. For models that have many features, we want to use multiple R-squared values, instead, because it will give a more accurate assessment of the model error if we have many dependent features instead of just one."
      ],
      "id": "480b36fa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bb92fcf"
      },
      "source": [
        "But what does this tell us as far as an error estimate for the model? We have standard error values from the output, but there’s an issue with the model being trained on all the data, then being tested on the same data. What we want to do, in order to ensure an unbiased amount of error, is to split our starting dataset into a training dataset and test dataset.\n",
        "\n",
        "In the world of statistics, you do this by taking a dataset you have and splitting it into 80% training data and 20% test data. You can tinker with those numbers to your taste, but you always want more training data than test data:"
      ],
      "id": "5bb92fcf"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "290431e9"
      },
      "source": [
        "split_size = 0.8\n",
        "\n",
        "sample_size = floor(split_size * nrow(mtcars))\n",
        "\n",
        "set.seed(123)\n",
        "train_indices <- sample(seq_len(nrow(mtcars)), size = sample_size)\n",
        "\n",
        "train <- mtcars[train_indices, ]\n",
        "test <- mtcars[-train_indices, ]"
      ],
      "id": "290431e9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9756d9ec"
      },
      "source": [
        "This example sets the split size at 80% and then the sample size for the training set to be 80% of the total number of rows in the `mtcars` data. We then set a seed for reproducibility, then get a list of row indices that we are going to put in our training data. We then split the training and test data by setting the training data to be the rows that contain those indices, and the test data is everything else."
      ],
      "id": "9756d9ec"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e549b66"
      },
      "source": [
        "What we want to do now is to build a regression model using only the training data. We then pass the test data values into it to get the model outputs. The key component here is that we have the known data against which we can test the model. That allows us to get a better level of error estimate out:"
      ],
      "id": "7e549b66"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "141a47f0"
      },
      "source": [
        "model2 <- lm(mpg ~ disp, data = train)\n",
        "\n",
        "new.data <- data.frame(disp = test$disp)\n",
        "\n",
        "test$output <- predict(model2, new.data)\n",
        "\n",
        "sqrt(sum(test$mpg - test$output)^2/nrow(test))"
      ],
      "id": "141a47f0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2af6011"
      },
      "source": [
        "Let’s walk through these steps to calculate the actual error of the model. Before, if you were to look at the residual standard error, you would see a value of 3.521. However, this value is dubious because it was calculated using the same data that was used to train the model. To remedy that, we’ve split the original `mtcars` data into a training set that we used exclusively for making the regression model, and a test set which we used to test against.\n",
        "\n",
        "First, we calculate a new linear model on the training data using `lm()`. Next, we form a data frame from our test data’s `disp` column. After that, we make predictions on our test set and store that in a new column in our test data. Finally, we compute a root-mean-square error (RMSE) term. We do this by taking the difference between our model output and the known mpg efficiency, squaring it, summing up those squares, and dividing by the total number of entries in the dataset. This gives us the value for the residual standard error. The new value is different from what we’ve seen before and is an important value for understanding how well our model is performing."
      ],
      "id": "a2af6011"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "120690a6"
      },
      "source": [
        "#### Question 3\n",
        "Repeat the linear regrssion with test and train dataset for `mpg` as a function of `hp` and print the coef and intercept. Use this to predict the fuel efficiency (`mpg`) of a car with `hp` of 200."
      ],
      "id": "120690a6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcea6418"
      },
      "source": [
        "### Classification\n",
        "In contrast to regression modeling, which you have likely previously done without realizing it, classification is a less frequently encountered part of the machine learning spectrum. Instead of predicting continuous values, like numbers, in classification exercises we’ll predict discrete values.\n",
        "\n",
        "#### Logistic Regression\n",
        "In contrast to regression, sometimes you want to see if a given data point is of a categorical nature instead of numeric. Before, we were given a numeric input and calculated a numeric output through a simple regression formula. Let's use the same mtcars dataset to visually explain the difference:"
      ],
      "id": "dcea6418"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4803a36f"
      },
      "source": [
        "plot(x = mtcars$mpg, y = mtcars$am, xlab = \"Fuel Efficiency (Miles per Gallon)\",\n",
        "    ylab = \"Vehicle Transmission Type (0 = Automatic, 1 = Manual)\")"
      ],
      "id": "4803a36f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91f7b88d"
      },
      "source": [
        "The data looks very different compared to what we saw earlier. In the `mtcars` dataset, each car is given a 0 or a 1 label to determine whether it has an automatic transmission as defined by the column name `am`. A car with an automatic has a value 1, whereas a manual transmission car has a value of 0. Fitting a linear regression model to this data would not work, because we cannot have half a transmission value. Instead, we need to rely on a logistic regression model to help classify whether new efficiency data belongs to either the automatic or manual transmission groups.\n",
        "\n",
        "We have a slightly different question to answer this time: how is the fuel efficiency related to a car’s transmission type? We can’t rely on the regression modeling procedure here, unfortunately. We could try to fit a regression line to the data, but the results would be very misleading. Instead, we need to use a classification algorithm. In this case, we will use a logistic regression algorithm.\n",
        "\n",
        "Logistic regression is different than linear regression in that we get discrete outputs instead of continuous ones. Before, we could get any number as a result of our regression model, but with our logistic model, we should expect a binary outcome for the transmission type; it either is an automatic transmission, or it isn’t. "
      ],
      "id": "91f7b88d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ec7b868"
      },
      "source": [
        "The approach here is different, as well. First, you need to load the `caTools` library:"
      ],
      "id": "4ec7b868"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72da77aa"
      },
      "source": [
        "install.packages(\"caTools\")\n",
        "install.packages(\"e1071\")"
      ],
      "id": "72da77aa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cb15146"
      },
      "source": [
        "library(caTools)\n",
        "library(e1071)"
      ],
      "id": "3cb15146",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "501856a3"
      },
      "source": [
        "This library contains many functions, but, most important, it has a function for logistic regression: `LogitBoost`. First, you need to give the model the label against which we want to predict as well as the data that you want to use for training the model:"
      ],
      "id": "501856a3"
    },
    {
      "cell_type": "code",
      "source": [
        "Label.train = train[,9]\n",
        "Data.train = train[,-9]"
      ],
      "metadata": {
        "id": "tnux4pRvFBoD"
      },
      "id": "tnux4pRvFBoD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71c69b9d"
      },
      "source": [
        "You can read the syntax of `train[,-9]` as follows: “The data we want is the `mtcars` dataset that we split into a training set earlier, except column number 9.” That happens to be the `am` column we used earlier. This is a more compact way of subsetting the data instead of listing out each column individually for input:"
      ],
      "id": "71c69b9d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b9e1e38"
      },
      "source": [
        "model = LogitBoost(Data.train, Label.train)\n",
        "Data.test = test\n",
        "Lab = predict(model, Data.test, type = \"raw\")\n",
        "data.frame(row.names(test), test$mpg, test$am, Lab)"
      ],
      "id": "8b9e1e38",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62babcdd"
      },
      "source": [
        "#### Supervised Clustering Methods"
      ],
      "id": "62babcdd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e487c88"
      },
      "source": [
        "Clustering is when you have a set of data and want to define classes based on how closely they are grouped. Sometimes, groupings of data might not be immediately obvious, and a clustering algorithm can help you find patterns where they might otherwise be difficult to see explicitly. Clustering is a good example of an ecosystem of algorithms that can be used both in a supervised and unsupervised case. It’s one of the most popular forms of classification, and one of the most popular clustering models is the `kmeans` algorithm."
      ],
      "id": "5e487c88"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e6b06d0"
      },
      "source": [
        "Let’s move into some biological data and examine Fisher's `iris` dataset by looking at the plot of petal width as a function of petal length:"
      ],
      "id": "8e6b06d0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "223b3d2b"
      },
      "source": [
        "plot(x = iris$Petal.Length, y = iris$Petal.Width, xlab = \"Petal Length\",\n",
        "    ylab = \"Petal Width\")"
      ],
      "id": "223b3d2b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f57d72b"
      },
      "source": [
        "What if we wanted to try to find three distinct groups in which to classify this dataset? The human brain is remarkably good at finding patterns and structure, so the clumping of data in the lower-left corner of the above plot stands out as one obvious cluster of data. But what about the rest? How do we go about breaking the data in the upper-right part of the plot into two more groups? One clustering algorithm that can accomplish this is the `kmeans()` approach to clustering."
      ],
      "id": "7f57d72b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d7032a5"
      },
      "source": [
        "This algorithm works by first placing a number of random test points in our data—in this case, two. Each of our real data points is measured as a distance from these test points, and then the test points are moved in a way to minimize that distance."
      ],
      "id": "0d7032a5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edff9172"
      },
      "source": [
        "data = data.frame(iris$Petal.Length, iris$Petal.Width)\n",
        "\n",
        "iris.kmeans <- kmeans(data, 2)\n",
        "\n",
        "plot(x = iris$Petal.Length, y = iris$Petal.Width, pch = iris.kmeans$cluster,\n",
        "    xlab = \"Petal Length\", ylab = \"Petal Width\")\n",
        "points(iris.kmeans$centers, pch = 8, cex = 2)"
      ],
      "id": "edff9172",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4813bed7"
      },
      "source": [
        "We can see how the algorithm works by splitting the data into two major groups. In the lower left is one cluster, denoted by the small triangles, and in the upper right there is another cluster labeled with circular data points. We see two big asterisks that mark where the cluster centers have finally stopped iterating. Any point that we further add to the data is marked as being in a cluster if it’s closer to one versus another. The points in the lower left are pretty well distinct from the others, but there is one outlier data point. Let’s use one more cluster to help make a little more sense of the data:"
      ],
      "id": "4813bed7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a8bb9cd"
      },
      "source": [
        "iris.kmeans3 <- kmeans(data, 3)\n",
        "\n",
        "plot(x = iris$Petal.Length, y = iris$Petal.Width, pch = iris.kmeans3$cluster,\n",
        "    xlab = \"Petal Length\", ylab = \"Petal Width\")\n",
        "\n",
        "points(iris.kmeans3$centers, pch = 8, cex = 2)"
      ],
      "id": "7a8bb9cd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72a3f34a"
      },
      "source": [
        "Now you can see that the larger group of data has been split further into two clusters of data that look to be about equal in size. There are three clusters in total with three different centers to the data. You could keep going by adding more and more cluster centers to the data, but you would be losing out on valuable information that way. If every single data point in the set were its own cluster, it would wind up being meaningless as far as classification goes i.e. it is said to be **over-fitted**. This is where you need to use a gut intuition to determine the appropriate level of fitting to the data. Too few clusters and the data is underfit: there isn’t a good way to determine structure. Too many clusters and you have the opposite problem: there’s far too much structure to make sense of simply."
      ],
      "id": "72a3f34a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbcf0da2"
      },
      "source": [
        "Fisher's dataset had three species of Iris in it. Let’s take compare our result to the actual species data answer and see how good our prediction really is:"
      ],
      "id": "cbcf0da2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41cba8de"
      },
      "source": [
        "par(mfrow = c(1, 2))\n",
        "\n",
        "plot(x = iris$Petal.Length, y = iris$Petal.Width, pch = iris.kmeans3$cluster,\n",
        "    xlab = \"Petal Length\", ylab = \"Petal Width\", main = \"Model Output\")\n",
        "\n",
        "plot(x = iris$Petal.Length, y = iris$Petal.Width,\n",
        "    pch = as.integer(iris$Species),\n",
        "    xlab = \"Petal Length\", ylab = \"Petal Width\", main = \"Actual Data\")\n"
      ],
      "id": "41cba8de",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dd279bb"
      },
      "source": [
        " It seems to be a fairly good match! We can see the same data represented in tabular format, called a confusion matrix:"
      ],
      "id": "1dd279bb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac8a070e"
      },
      "source": [
        "table(iris.kmeans3$cluster, iris$Species)"
      ],
      "id": "ac8a070e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f20604d2"
      },
      "source": [
        "You can read this confusion matrix with the output clusters as the rows, and the actual values from the data as the columns. It shows that there are only six predictions that were off in cluster 1, and two predictions that were off in cluster 3. A perfect machine learning model would have zeroes for all the off-diagonal elements, but this is pretty good for an illustrative example."
      ],
      "id": "f20604d2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef974324"
      },
      "source": [
        "#### Tree-Based Models\n",
        "So far, we’ve seen a linear regression and logistic regression example. Part of the universe of machine learning models includes tree-based methods. Simply put, a tree is a structure that has nodes and edges. For a decision tree, at each node we might have a value against which we split in order to gain some insight from the data."
      ],
      "id": "ef974324"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91497762"
      },
      "source": [
        "install.packages(\"party\")"
      ],
      "id": "91497762",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d7b0338"
      },
      "source": [
        "library(party)\n",
        "tree <- ctree(mpg ~ ., data = mtcars)\n",
        "plot(tree)"
      ],
      "id": "4d7b0338",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f2cb854"
      },
      "source": [
        "The above plot demonstrates a plotted conditional inference tree. We are plotting engine fuel efficiency (mpg), but we’re using all features in the dataset to build the model instead of just one; hence, the mpg ~ . call in the `ctree()` function. The output is a distribution (in the form of a box-and-whisker plot) of the fuel efficency as a function of the major features that influence it. The ctree function calls on certain methods to figure these out; this way, you don’t have a bunch of branches in the tree that don’t amount to anything other than to clog up the view. In this case, the features that are most important to mpg are disp (the engine displacement) and wt (the car’s weight). You read this chart from top to bottom.\n",
        "\n",
        "At node 1, there is a split for cars that weigh less than 2.32 tons and those that weigh more. For the cars that weigh more, we split further on the engine displacement. For engine displacements that are less than 258 cubic inches in volume, we go to node 4. For engine displacements that have more than 258 cubic inches, we go to node 5. Notice that for each feature there is a statistical p-value, which determines how statistically relevant it is. The closer the p-value is to 0.05 or greater, the less useful or relevant it is. In this case, a p-value of almost exactly 0 is very good. Likewise, you can see how many data points make up each class at the bottom of the tree.\n",
        "\n",
        "Let’s consider a car that has a weight of four tons, and a small engine size of 100 cubic inches. At node 1, we go along the righthand path to node 3 (because the weight is greater than 2.32 tons) and then go left to node 4 based on the theoretical data we just made up. We should expect the fuel efficiency of this car to be somewhere between 13 and 25 miles per gallon.\n",
        "\n",
        "What if you try to use this new data structure for prediction? The first thing that should pop up is that you are looking at the entire dataset instead of just the training data"
      ],
      "id": "3f2cb854"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bf725a8"
      },
      "source": [
        "tree.train <- ctree(mpg ~ ., data = train)\n",
        "plot(tree.train)"
      ],
      "id": "1bf725a8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dd5d2fa"
      },
      "source": [
        "By looking at just the training data, you have a slightly different picture in that the tree depends only on the car’s weight. In the following example, there are only two classes instead of the tree as before:"
      ],
      "id": "1dd5d2fa"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dff2d510"
      },
      "source": [
        "test$mpg.tree <- predict(tree.train, test)\n",
        "test$class <- predict(tree.train, test, type = \"node\")\n",
        "data.frame(row.names(test), test$mpg, test$mpg.tree, test$class)"
      ],
      "id": "dff2d510",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "240f8636"
      },
      "source": [
        "This chunk of code does both a regression and a classification test in two easy lines of code. First, it takes the familiar predict() function and applies it to the entirety of the test data and then stores it as a column in the test data. Then, it performs the same procedure, but adds the type=\"node\" option to the predict() function to get a class out. It then sticks them all together in a single data frame.\n",
        "\n",
        "What you can see from the end result is that it doesn’t take a lot of work for some algorithms to provide both a continuous, numeric output (regression) as well as a discrete class output (classification) for the same input data."
      ],
      "id": "240f8636"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b50d511"
      },
      "source": [
        "#### Support Vector Machines\n",
        "Support vector machines, or SVMs, are another algorithm that you can use for both regression and classification. Oftentimes, it is introduced as a simpler or faster corollary to a neural network. SVMs work in a manner that’s similar in many respects to logistic regression. The idea is that we are taking data and trying to find a plane or a line that can separate the data into different classes."
      ],
      "id": "5b50d511"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d321bba"
      },
      "source": [
        "Suppose that you have n features in your data and m observations, or rows. If n is much greater than m (e.g., n = 1,000 , m = 10), you would want to use a logistic regressor. If you have the opposite (e.g., n = 10, m = 1,000), you might want to use an SVM instead.\n",
        "\n",
        "Alternatively, you can use a neural network for either case, but it might be considerably slower to train than one of these specific algorithms.\n",
        "\n",
        "You can do SVM classification in a very similar manner to neural network classification, like we saw previously:"
      ],
      "id": "6d321bba"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc52cc4a"
      },
      "source": [
        "library(e1071)\n",
        "iris.svm <- svm(Species ~ ., data = iris)\n",
        "table(iris$Species, predict(iris.svm, iris, type = \"class\"))"
      ],
      "id": "fc52cc4a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa132861"
      },
      "source": [
        "Better than the logisitic regression model!"
      ],
      "id": "fa132861"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdAjaKiZ48wf"
      },
      "source": [
        "## 3.0 Introduction to machine learning - unsupervised methods"
      ],
      "id": "gdAjaKiZ48wf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b037e456"
      },
      "source": [
        "### Unsupervised Learning\n",
        "So far, with supervised learning algorithms, we’ve taken a set of data, broken it into a training and a test set, trained the model, and then evaluated its performance with the test data. Unsupervised learning algorithms take a different approach in that they try to define the overall structure of the data. In principle, these won’t have a test set against which to evaluate the model’s performance.\n",
        "\n",
        "Generally, most machine learning models you’ll encounter will be supervised learning approaches. You build a model, train and test the data, and then compare the outputs to some known parameters. Unsupervised learning doesn’t have any “answer” value against which we compare to score the model. Model evaluation and scoring is done in a slightly different manner in this regard. One example of which can be text mining. An unsupervised learner modeled on text from all of Abraham Lincoln’s writings might be used to try to build an artificial intelligence (AI) that would write documents like he would author, based on word frequency and proximity to other words. Implicitly, there’s no immediate “right” answer against which you would evaluate your Abraham Lincoln bot. Instead, you would need to score that case by what kind of contextual sense the model would generate.\n",
        "\n",
        "The most common form of unsupervised learning is clustering. We’ve seen clustering in action already, masked in an example of supervised learning. We were able to run with that example because we had an answer key to use for comparison. But what if we didn’t have some data for which we knew the answer?"
      ],
      "id": "b037e456"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ea294507"
      },
      "source": [
        "In this unsupervised version of clustering, you are going to take data that has no explicit categorical label and try to categorize them yourself. If you generate some random data, you don’t really know how it will cluster up. You can perform the usual kmeans clustering algorithm here to see how the data should be classified:"
      ],
      "id": "ea294507"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3402a96"
      },
      "source": [
        "x <- rbind(matrix(rnorm(100, sd = 0.3), ncol = 2), matrix(rnorm(100,\n",
        "    mean = 1, sd = 0.3), ncol = 2))\n",
        "\n",
        "colnames(x) <- c(\"x\", \"y\")\n",
        "\n",
        "\n",
        "plot(x)"
      ],
      "id": "b3402a96",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdd110c9"
      },
      "source": [
        "What we’ve done here is generate a random set of data that is normally distributed into two groups. In this case, it might be a little tougher to see where the exact groupings are, but luckily the kmeans algorithm can help designate which points belong to which group:"
      ],
      "id": "bdd110c9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3c147d32"
      },
      "source": [
        "cl <- kmeans(x, 2)\n",
        "\n",
        "plot(x, pch = cl$cluster)"
      ],
      "id": "3c147d32",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64cdc7a9"
      },
      "source": [
        "However, because the dataset has no explicit label tagged to it prior to applying the kmeans classification, the best you can do is to label future data points according to the clustering centers. You can see those by printing them out from the cl variable: "
      ],
      "id": "64cdc7a9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41577b31"
      },
      "source": [
        "cl[2]"
      ],
      "id": "41577b31",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ef60cfb"
      },
      "source": [
        "Row 1 denotes the x,y coordinates of the first cluster, and likewise for row 2. Any point that you add to the dataset that is closer to either of these cluster centers will be labeled accordingly."
      ],
      "id": "2ef60cfb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b693a6b6"
      },
      "source": [
        "### End of workbook C\n",
        "\n",
        "In this practical we took some cursory glances at the difference between regression (continuous data in, continuous data out), and classification (discrete data in, discrete data out). There are many machine learning algorithms that you can use for both, details of which we explore at in next weeks practical.\n",
        "\n",
        "For supervised learning, we covered the most popular algorithms and how to implement them at a very basic level:\n",
        "\n",
        "Linear regression, `lm()`, for defining a simple equation by which you can describe a relationship between an output and a number of features attributed to it\n",
        "\n",
        "Logistic regression, `LogitBoost()`, for determining a way to separate numeric data into classes\n",
        "\n",
        "k-means clustering, `kmeans()`, for developing clusters and labeling data according to how those clusters evolve\n",
        "\n",
        "Conditional inference trees, `ctree()`, for defining splits in data and performing regressions or classifications on the split data\n",
        "\n",
        "Support vector machines, `svm()`, for when you might have fewer features than observations and aren’t getting good results from logistic regression"
      ],
      "id": "b693a6b6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e81c36d6"
      },
      "source": [
        "#### Question 4\n",
        "Repeat the steps of this practical performed with the mtcars dataset with the Iris dataset and vice versa to get used to running the functions with different data.\n",
        "Submit your notebook or R script with the substituted data to the discussion board."
      ],
      "id": "e81c36d6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eb55516a"
      },
      "source": [
        ""
      ],
      "id": "eb55516a",
      "execution_count": null,
      "outputs": []
    }
  ]
}